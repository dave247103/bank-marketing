# Bank Marketing Report

## Goal
Predict term deposit subscription (y=yes/no) with batch ML training and a real-time scoring pipeline.

## Data
- Raw input: data/raw/bank-full.csv
- Processed dataset: data/processed/bank.parquet (generated by ETL)

## ETL
- Script: src/etl/etl_bank.py
- Output: data/processed/bank.parquet
- Summary: basic cleaning, schema normalization, and label preparation for Spark ML.

## EDA
- Summary write-up: report/eda.md
- Figure: fireport/gures/label_distribution.png

## 3-model comparison
- Metrics artifact: metrics_models.json
- Table: tables.md (Model comparison)
- Figure: report/figures/model_comparison.png

## Evaluation
- Confusion matrices and classification metrics in metrics_models.json and metrics_tuning_*.json
- Holdout split details are recorded in the metrics JSON files.

## Tuning
- Tuning artifacts: metrics_tuning_gbt.json, metrics_tuning_rf.json
- Table: tables.md (Tuning metrics and params)

## Feature importance
- CSV: feature_importance_gbt.csv
- Figure: report/figures/feature_importance_top20.png

## Streaming pipeline
- Architecture: Producer -> Kafka(bank_raw) -> Spark Structured Streaming scorer -> Kafka(bank_scored) -> Consumer
- Dead-letter topic: Kafka(bank_deadletter)
- Scripts: src/streaming/producer.py, src/streaming/scorer.py, src/streaming/consumer.py
- Run script: scripts/run_stream_latency.sh

## Performance
- Latency summary: stream_latency.json
- Progress summary: stream_summary.json
- Figure: report/figures/stream_latency_hist.png
- Table: tables.md (Streaming latency)

## Conclusions
- Summarize the best-performing model and any trade-offs.
- Note streaming performance and operational considerations.
- Call out remaining limitations or future work.

## Sources
- UCI Bank Marketing dataset (bank-full.csv)
- Spark MLlib and Kafka documentation
